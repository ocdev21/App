{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfluxDB Integration Testing with AWS Bedrock\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Connecting to AWS Timestream for InfluxDB\n",
    "- Writing test data to InfluxDB buckets\n",
    "- Querying time-series data\n",
    "- Analyzing data with Bedrock AI (Claude 3)\n",
    "- Visualizing metrics with Plotly\n",
    "\n",
    "## Prerequisites\n",
    "- IAM role with permissions for Bedrock\n",
    "- InfluxDB credentials stored in environment variables or AWS Secrets Manager\n",
    "- Required Python packages installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if not already installed)\n",
    "!pip install -q influxdb-client==1.49.0 boto3 pandas plotly ipywidgets aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set up InfluxDB and AWS credentials. You can either:\n",
    "- Set environment variables directly\n",
    "- Load from AWS Secrets Manager\n",
    "- Enter manually in the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InfluxDB Configuration\n",
    "INFLUXDB_URL = os.getenv('INFLUXDB_URL', 'https://Lhk52q7uoe-lktzzbuyksah47.timestream-influxdb.us-east-1.on.aws')\n",
    "INFLUXDB_TOKEN = os.getenv('INFLUXDB_TOKEN', '')  # Set your token here or in environment\n",
    "INFLUXDB_ORG = os.getenv('INFLUXDB_ORG', 'superapp-org')\n",
    "INFLUXDB_BUCKET = os.getenv('INFLUXDB_BUCKET', 'test-bucket')\n",
    "\n",
    "# AWS Configuration\n",
    "AWS_REGION = 'us-east-1'\n",
    "BEDROCK_MODEL_ID = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "print(f\"✓ InfluxDB URL: {INFLUXDB_URL}\")\n",
    "print(f\"✓ InfluxDB Org: {INFLUXDB_ORG}\")\n",
    "print(f\"✓ InfluxDB Bucket: {INFLUXDB_BUCKET}\")\n",
    "print(f\"✓ AWS Region: {AWS_REGION}\")\n",
    "print(f\"✓ Token configured: {'Yes' if INFLUXDB_TOKEN else 'No - Please set INFLUXDB_TOKEN'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Load credentials from AWS Secrets Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to load from Secrets Manager\n",
    "# def load_influxdb_credentials_from_secrets_manager():\n",
    "#     secrets_client = boto3.client('secretsmanager', region_name=AWS_REGION)\n",
    "#     try:\n",
    "#         response = secrets_client.get_secret_value(SecretId='superapp-influxdb-credentials')\n",
    "#         secrets = json.loads(response['SecretString'])\n",
    "#         return secrets\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading secrets: {e}\")\n",
    "#         return None\n",
    "\n",
    "# Load and update configuration\n",
    "# secrets = load_influxdb_credentials_from_secrets_manager()\n",
    "# if secrets:\n",
    "#     INFLUXDB_URL = secrets.get('INFLUXDB_URL', INFLUXDB_URL)\n",
    "#     INFLUXDB_TOKEN = secrets.get('INFLUXDB_TOKEN', INFLUXDB_TOKEN)\n",
    "#     INFLUXDB_ORG = secrets.get('INFLUXDB_ORG', INFLUXDB_ORG)\n",
    "#     INFLUXDB_BUCKET = secrets.get('INFLUXDB_BUCKET', INFLUXDB_BUCKET)\n",
    "#     print(\"✓ Credentials loaded from Secrets Manager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize InfluxDB client\n",
    "influx_client = InfluxDBClient(\n",
    "    url=INFLUXDB_URL,\n",
    "    token=INFLUXDB_TOKEN,\n",
    "    org=INFLUXDB_ORG,\n",
    "    timeout=30_000  # 30 second timeout\n",
    ")\n",
    "\n",
    "# Create API instances\n",
    "write_api = influx_client.write_api(write_options=SYNCHRONOUS)\n",
    "query_api = influx_client.query_api()\n",
    "health_api = influx_client.health()\n",
    "\n",
    "print(f\"✓ InfluxDB Health Status: {health_api.status}\")\n",
    "print(f\"✓ InfluxDB Version: {health_api.version if hasattr(health_api, 'version') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AWS Bedrock client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "print(\"✓ AWS Bedrock client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Data Writing\n",
    "\n",
    "Write sample energy metrics and sensor data to InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sample_energy_metrics(count=10):\n",
    "    \"\"\"\n",
    "    Write sample energy metrics to InfluxDB\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    points = []\n",
    "    base_time = datetime.utcnow() - timedelta(hours=1)\n",
    "    \n",
    "    for i in range(count):\n",
    "        timestamp = base_time + timedelta(minutes=i * 6)\n",
    "        \n",
    "        point = (\n",
    "            Point(\"energy_metrics\")\n",
    "            .tag(\"location\", \"datacenter-1\")\n",
    "            .tag(\"source\", \"jupyter-test\")\n",
    "            .field(\"power_kw\", round(random.uniform(50, 150), 2))\n",
    "            .field(\"voltage\", round(random.uniform(220, 240), 2))\n",
    "            .field(\"current\", round(random.uniform(10, 30), 2))\n",
    "            .field(\"temperature\", round(random.uniform(20, 35), 2))\n",
    "            .time(timestamp, WritePrecision.NS)\n",
    "        )\n",
    "        points.append(point)\n",
    "    \n",
    "    try:\n",
    "        write_api.write(bucket=INFLUXDB_BUCKET, org=INFLUXDB_ORG, record=points)\n",
    "        print(f\"✓ Successfully wrote {count} energy metric points\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error writing data: {e}\")\n",
    "        return False\n",
    "\n",
    "# Write sample data\n",
    "write_sample_energy_metrics(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sample_sensor_data(count=10):\n",
    "    \"\"\"\n",
    "    Write sample sensor data to InfluxDB\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    points = []\n",
    "    base_time = datetime.utcnow() - timedelta(hours=1)\n",
    "    \n",
    "    for i in range(count):\n",
    "        timestamp = base_time + timedelta(minutes=i * 6)\n",
    "        \n",
    "        point = (\n",
    "            Point(\"sensor_data\")\n",
    "            .tag(\"sensor_id\", f\"sensor-{random.randint(1, 3)}\")\n",
    "            .tag(\"source\", \"jupyter-test\")\n",
    "            .field(\"temperature\", round(random.uniform(15, 30), 2))\n",
    "            .field(\"humidity\", round(random.uniform(30, 70), 2))\n",
    "            .field(\"pressure\", round(random.uniform(980, 1020), 2))\n",
    "            .time(timestamp, WritePrecision.NS)\n",
    "        )\n",
    "        points.append(point)\n",
    "    \n",
    "    try:\n",
    "        write_api.write(bucket=INFLUXDB_BUCKET, org=INFLUXDB_ORG, record=points)\n",
    "        print(f\"✓ Successfully wrote {count} sensor data points\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error writing data: {e}\")\n",
    "        return False\n",
    "\n",
    "# Write sample data\n",
    "write_sample_sensor_data(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Query and Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_energy_metrics(hours=1):\n",
    "    \"\"\"\n",
    "    Query energy metrics from InfluxDB\n",
    "    \"\"\"\n",
    "    flux_query = f'''\n",
    "    from(bucket: \"{INFLUXDB_BUCKET}\")\n",
    "      |> range(start: -{hours}h)\n",
    "      |> filter(fn: (r) => r._measurement == \"energy_metrics\")\n",
    "      |> filter(fn: (r) => r._field == \"power_kw\" or r._field == \"temperature\")\n",
    "      |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        tables = query_api.query(flux_query, org=INFLUXDB_ORG)\n",
    "        \n",
    "        # Convert to pandas DataFrame\n",
    "        records = []\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                records.append({\n",
    "                    'time': record.get_time(),\n",
    "                    'location': record.values.get('location'),\n",
    "                    'power_kw': record.values.get('power_kw'),\n",
    "                    'temperature': record.values.get('temperature')\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(records)\n",
    "        print(f\"✓ Retrieved {len(df)} energy metric records\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error querying data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Query data\n",
    "energy_df = query_energy_metrics(hours=2)\n",
    "if not energy_df.empty:\n",
    "    display(energy_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize energy metrics\n",
    "if not energy_df.empty:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add power trace\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=energy_df['time'],\n",
    "        y=energy_df['power_kw'],\n",
    "        mode='lines+markers',\n",
    "        name='Power (kW)',\n",
    "        line=dict(color='#3b82f6', width=2)\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Energy Consumption Over Time',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Power (kW)',\n",
    "        hovermode='x unified',\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sensor_data(hours=1):\n",
    "    \"\"\"\n",
    "    Query sensor data from InfluxDB\n",
    "    \"\"\"\n",
    "    flux_query = f'''\n",
    "    from(bucket: \"{INFLUXDB_BUCKET}\")\n",
    "      |> range(start: -{hours}h)\n",
    "      |> filter(fn: (r) => r._measurement == \"sensor_data\")\n",
    "      |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        tables = query_api.query(flux_query, org=INFLUXDB_ORG)\n",
    "        \n",
    "        records = []\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                records.append({\n",
    "                    'time': record.get_time(),\n",
    "                    'sensor_id': record.values.get('sensor_id'),\n",
    "                    'temperature': record.values.get('temperature'),\n",
    "                    'humidity': record.values.get('humidity'),\n",
    "                    'pressure': record.values.get('pressure')\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(records)\n",
    "        print(f\"✓ Retrieved {len(df)} sensor data records\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error querying data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Query sensor data\n",
    "sensor_df = query_sensor_data(hours=2)\n",
    "if not sensor_df.empty:\n",
    "    display(sensor_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sensor data by sensor\n",
    "if not sensor_df.empty:\n",
    "    fig = px.line(\n",
    "        sensor_df,\n",
    "        x='time',\n",
    "        y='temperature',\n",
    "        color='sensor_id',\n",
    "        title='Sensor Temperature Readings',\n",
    "        labels={'temperature': 'Temperature (°C)', 'time': 'Time'},\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    fig.update_layout(height=400)\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No sensor data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. AI Analysis with AWS Bedrock\n",
    "\n",
    "Use Claude 3 to analyze the time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_bedrock_claude(prompt, max_tokens=2048):\n",
    "    \"\"\"\n",
    "    Invoke Claude 3 via Bedrock for data analysis\n",
    "    \"\"\"\n",
    "    body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=BEDROCK_MODEL_ID,\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        return response_body['content'][0]['text']\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error invoking Bedrock: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data summary for AI analysis\n",
    "if not energy_df.empty:\n",
    "    stats = energy_df['power_kw'].describe()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following energy consumption data and provide insights:\n",
    "    \n",
    "    Data Summary:\n",
    "    - Total readings: {len(energy_df)}\n",
    "    - Time period: {energy_df['time'].min()} to {energy_df['time'].max()}\n",
    "    - Average power: {stats['mean']:.2f} kW\n",
    "    - Min power: {stats['min']:.2f} kW\n",
    "    - Max power: {stats['max']:.2f} kW\n",
    "    - Std deviation: {stats['std']:.2f} kW\n",
    "    \n",
    "    Please provide:\n",
    "    1. Key observations about the energy consumption pattern\n",
    "    2. Any anomalies or unusual patterns\n",
    "    3. Recommendations for optimization\n",
    "    4. Potential cost-saving opportunities\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Analyzing data with Claude 3...\\n\")\n",
    "    analysis = invoke_bedrock_claude(prompt)\n",
    "    \n",
    "    if analysis:\n",
    "        display(Markdown(\"## AI Analysis Results\\n\\n\" + analysis))\n",
    "else:\n",
    "    print(\"No energy data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Testing Widget\n",
    "\n",
    "Interactive interface for writing and querying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widgets\n",
    "measurement_dropdown = widgets.Dropdown(\n",
    "    options=['energy_metrics', 'sensor_data'],\n",
    "    value='energy_metrics',\n",
    "    description='Measurement:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "write_count = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Data Points:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "query_hours = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=24,\n",
    "    step=1,\n",
    "    description='Query Hours:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "write_button = widgets.Button(\n",
    "    description='Write Test Data',\n",
    "    button_style='success',\n",
    "    icon='database'\n",
    ")\n",
    "\n",
    "query_button = widgets.Button(\n",
    "    description='Query Data',\n",
    "    button_style='info',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "analyze_button = widgets.Button(\n",
    "    description='AI Analysis',\n",
    "    button_style='warning',\n",
    "    icon='brain'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_write_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(f\"Writing {write_count.value} points to {measurement_dropdown.value}...\")\n",
    "        \n",
    "        if measurement_dropdown.value == 'energy_metrics':\n",
    "            write_sample_energy_metrics(write_count.value)\n",
    "        else:\n",
    "            write_sample_sensor_data(write_count.value)\n",
    "\n",
    "def on_query_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(f\"Querying {measurement_dropdown.value} for last {query_hours.value} hour(s)...\")\n",
    "        \n",
    "        if measurement_dropdown.value == 'energy_metrics':\n",
    "            df = query_energy_metrics(query_hours.value)\n",
    "        else:\n",
    "            df = query_sensor_data(query_hours.value)\n",
    "        \n",
    "        if not df.empty:\n",
    "            display(df.head(10))\n",
    "            print(f\"\\nTotal records: {len(df)}\")\n",
    "\n",
    "def on_analyze_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Running AI analysis...\\n\")\n",
    "        \n",
    "        if measurement_dropdown.value == 'energy_metrics':\n",
    "            df = query_energy_metrics(query_hours.value)\n",
    "            if not df.empty:\n",
    "                stats = df['power_kw'].describe()\n",
    "                prompt = f\"Analyze this energy data: mean={stats['mean']:.2f}kW, min={stats['min']:.2f}kW, max={stats['max']:.2f}kW. Provide brief insights.\"\n",
    "                analysis = invoke_bedrock_claude(prompt, max_tokens=500)\n",
    "                if analysis:\n",
    "                    display(Markdown(analysis))\n",
    "\n",
    "write_button.on_click(on_write_button_clicked)\n",
    "query_button.on_click(on_query_button_clicked)\n",
    "analyze_button.on_click(on_analyze_button_clicked)\n",
    "\n",
    "# Display widgets\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>InfluxDB Interactive Testing</h3>\"),\n",
    "    measurement_dropdown,\n",
    "    write_count,\n",
    "    query_hours,\n",
    "    widgets.HBox([write_button, query_button, analyze_button]),\n",
    "    output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Testing\n",
    "\n",
    "Test write and query performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_test_write(num_points=100):\n",
    "    \"\"\"\n",
    "    Test InfluxDB write performance\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    print(f\"Performance test: Writing {num_points} points...\")\n",
    "    \n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        point = (\n",
    "            Point(\"perf_test\")\n",
    "            .tag(\"test_id\", \"performance\")\n",
    "            .field(\"value\", random.random() * 100)\n",
    "            .field(\"iteration\", i)\n",
    "        )\n",
    "        points.append(point)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        write_api.write(bucket=INFLUXDB_BUCKET, org=INFLUXDB_ORG, record=points)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        print(f\"✓ Wrote {num_points} points in {elapsed:.3f} seconds\")\n",
    "        print(f\"  Throughput: {num_points/elapsed:.1f} points/second\")\n",
    "        return elapsed\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Write failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run performance test\n",
    "performance_test_write(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_test_query():\n",
    "    \"\"\"\n",
    "    Test InfluxDB query performance\n",
    "    \"\"\"\n",
    "    flux_query = f'''\n",
    "    from(bucket: \"{INFLUXDB_BUCKET}\")\n",
    "      |> range(start: -24h)\n",
    "      |> filter(fn: (r) => r._measurement == \"perf_test\")\n",
    "      |> count()\n",
    "    '''\n",
    "    \n",
    "    print(\"Performance test: Querying data...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        tables = query_api.query(flux_query, org=INFLUXDB_ORG)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        total_records = sum([len(table.records) for table in tables])\n",
    "        print(f\"✓ Query completed in {elapsed:.3f} seconds\")\n",
    "        print(f\"  Records processed: {total_records}\")\n",
    "        return elapsed\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Query failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run query performance test\n",
    "performance_test_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup and Close Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close InfluxDB client\n",
    "influx_client.close()\n",
    "print(\"✓ InfluxDB client closed\")\n",
    "print(\"\\nTesting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- ✓ Connecting to AWS Timestream for InfluxDB\n",
    "- ✓ Writing time-series data (energy metrics and sensor data)\n",
    "- ✓ Querying data using Flux query language\n",
    "- ✓ Visualizing metrics with Plotly\n",
    "- ✓ AI-powered data analysis with AWS Bedrock (Claude 3)\n",
    "- ✓ Interactive testing interface with ipywidgets\n",
    "- ✓ Performance testing\n",
    "\n",
    "### Next Steps\n",
    "1. Customize the data models for your specific use case\n",
    "2. Implement more advanced Flux queries and aggregations\n",
    "3. Set up automated data collection pipelines\n",
    "4. Create dashboards for real-time monitoring\n",
    "5. Integrate with other AWS services (Lambda, Step Functions, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
