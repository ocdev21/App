{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude 3 AI Chat - Interactive Interface\n",
    "\n",
    "This notebook provides an interactive chat interface with Claude 3 AI via AWS Bedrock.\n",
    "\n",
    "## Features:\n",
    "- Real-time streaming responses\n",
    "- Character counter (0-10,000 characters)\n",
    "- Interactive widgets for easy use\n",
    "- Error handling with helpful messages\n",
    "\n",
    "**Prerequisites:** Run `00_setup.ipynb` first to validate your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# Add modules directory to path\n",
    "sys.path.insert(0, os.path.abspath('../modules'))\n",
    "\n",
    "from bedrock_streaming import BedrockClient\n",
    "\n",
    "print(\"‚úÖ Modules loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize Bedrock Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "AWS_REGION = os.getenv('AWS_REGION', 'us-east-1')\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock = BedrockClient(region_name=AWS_REGION)\n",
    "\n",
    "print(f\"‚úÖ Bedrock client initialized\")\n",
    "print(f\"   Region: {AWS_REGION}\")\n",
    "print(f\"   Model: anthropic.claude-3-sonnet-20240229-v1:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Interactive Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widgets\n",
    "prompt_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Ask Claude 3 anything... (e.g., \"Explain quantum computing in simple terms\")',\n",
    "    description='Your Prompt:',\n",
    "    layout=widgets.Layout(width='95%', height='120px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "char_counter = widgets.HTML(\n",
    "    value='<p style=\"color: #666; font-size: 12px;\">0 / 10000 characters</p>'\n",
    ")\n",
    "\n",
    "submit_btn = widgets.Button(\n",
    "    description='Submit',\n",
    "    button_style='primary',\n",
    "    icon='paper-plane',\n",
    "    layout=widgets.Layout(width='120px')\n",
    ")\n",
    "\n",
    "clear_btn = widgets.Button(\n",
    "    description='Clear',\n",
    "    button_style='',\n",
    "    icon='trash',\n",
    "    layout=widgets.Layout(width='120px')\n",
    ")\n",
    "\n",
    "response_output = widgets.Output(\n",
    "    layout=widgets.Layout(\n",
    "        width='95%',\n",
    "        height='400px',\n",
    "        border='1px solid #ddd',\n",
    "        padding='15px',\n",
    "        overflow_y='auto'\n",
    "    )\n",
    ")\n",
    "\n",
    "status_output = widgets.HTML(\n",
    "    value='<p style=\"color: #666; font-size: 12px;\">Ready to chat with Claude 3</p>'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Widgets created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Event Handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_char_counter(change):\n",
    "    \"\"\"Update character counter when prompt changes\"\"\"\n",
    "    length = len(change['new'])\n",
    "    color = '#d32f2f' if length > 10000 else '#666'\n",
    "    char_counter.value = f'<p style=\"color: {color}; font-size: 12px;\">{length} / 10000 characters</p>'\n",
    "    \n",
    "    # Disable submit if over limit or empty\n",
    "    submit_btn.disabled = length == 0 or length > 10000\n",
    "\n",
    "def on_submit_click(b):\n",
    "    \"\"\"Handle submit button click\"\"\"\n",
    "    prompt = prompt_input.value.strip()\n",
    "    \n",
    "    if not prompt:\n",
    "        with response_output:\n",
    "            clear_output()\n",
    "            print(\"‚ö†Ô∏è  Please enter a prompt\")\n",
    "        return\n",
    "    \n",
    "    if len(prompt) > 10000:\n",
    "        with response_output:\n",
    "            clear_output()\n",
    "            print(\"‚ö†Ô∏è  Prompt exceeds 10,000 character limit\")\n",
    "        return\n",
    "    \n",
    "    # Disable buttons during processing\n",
    "    submit_btn.disabled = True\n",
    "    clear_btn.disabled = True\n",
    "    prompt_input.disabled = True\n",
    "    \n",
    "    # Update status\n",
    "    status_output.value = '<p style=\"color: #1976d2; font-size: 12px;\">‚è≥ Claude is thinking...</p>'\n",
    "    \n",
    "    # Clear previous response\n",
    "    with response_output:\n",
    "        clear_output()\n",
    "        print(f\"ü§ñ Claude 3 Response:\\n\")\n",
    "        print(\"Streaming response...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Stream response\n",
    "        full_response = \"\"\n",
    "        for chunk in bedrock.invoke_streaming(prompt):\n",
    "            full_response += chunk\n",
    "            with response_output:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"ü§ñ Claude 3 Response:\\n\")\n",
    "                print(full_response)\n",
    "                print(\"\\n[Streaming...]\")\n",
    "        \n",
    "        # Final update\n",
    "        with response_output:\n",
    "            clear_output()\n",
    "            print(f\"ü§ñ Claude 3 Response:\\n\")\n",
    "            print(full_response)\n",
    "            print(f\"\\n---\\nCompleted at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        status_output.value = f'<p style=\"color: #2e7d32; font-size: 12px;\">‚úÖ Response complete ({len(full_response)} characters)</p>'\n",
    "    \n",
    "    except Exception as e:\n",
    "        with response_output:\n",
    "            clear_output()\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "            print(\"\\nPlease check:\")\n",
    "            print(\"- Your SageMaker execution role has Bedrock permissions\")\n",
    "            print(\"- You're in a supported region (us-east-1 or us-west-2)\")\n",
    "            print(\"- Claude 3 model access is enabled in your AWS account\")\n",
    "        \n",
    "        status_output.value = '<p style=\"color: #d32f2f; font-size: 12px;\">‚ùå Error occurred</p>'\n",
    "    \n",
    "    finally:\n",
    "        # Re-enable buttons\n",
    "        submit_btn.disabled = False\n",
    "        clear_btn.disabled = False\n",
    "        prompt_input.disabled = False\n",
    "\n",
    "def on_clear_click(b):\n",
    "    \"\"\"Handle clear button click\"\"\"\n",
    "    prompt_input.value = ''\n",
    "    with response_output:\n",
    "        clear_output()\n",
    "    status_output.value = '<p style=\"color: #666; font-size: 12px;\">Ready to chat with Claude 3</p>'\n",
    "\n",
    "# Attach event handlers\n",
    "prompt_input.observe(update_char_counter, names='value')\n",
    "submit_btn.on_click(on_submit_click)\n",
    "clear_btn.on_click(on_clear_click)\n",
    "\n",
    "print(\"‚úÖ Event handlers configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Display Chat Interface\n",
    "\n",
    "Run this cell to display the interactive chat interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display header\n",
    "display(Markdown(\"## üí¨ Chat with Claude 3\"))\n",
    "display(Markdown(\"_Powered by AWS Bedrock_\"))\n",
    "display(Markdown(\"---\"))\n",
    "\n",
    "# Display prompt input section\n",
    "display(Markdown(\"### Your Prompt\"))\n",
    "display(prompt_input)\n",
    "display(char_counter)\n",
    "\n",
    "# Display buttons\n",
    "button_box = widgets.HBox([submit_btn, clear_btn], layout=widgets.Layout(margin='10px 0'))\n",
    "display(button_box)\n",
    "\n",
    "# Display status\n",
    "display(status_output)\n",
    "\n",
    "# Display response section\n",
    "display(Markdown(\"### AI Response\"))\n",
    "display(response_output)\n",
    "\n",
    "# Display tips\n",
    "display(Markdown(\"\"\"\n",
    "---\n",
    "### üí° Tips:\n",
    "- Enter your prompt in the text area above\n",
    "- Watch the response stream in real-time\n",
    "- Max prompt length: 10,000 characters\n",
    "- Use Clear to reset and start a new conversation\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Prompts\n",
    "\n",
    "Try these example prompts:\n",
    "\n",
    "1. **Technical Explanation:**  \n",
    "   \"Explain how AWS Bedrock works in simple terms\"\n",
    "\n",
    "2. **Code Help:**  \n",
    "   \"Write a Python function to calculate Fibonacci numbers using recursion\"\n",
    "\n",
    "3. **Data Science:**  \n",
    "   \"What are the key differences between supervised and unsupervised learning?\"\n",
    "\n",
    "4. **Creative Writing:**  \n",
    "   \"Write a haiku about cloud computing\"\n",
    "\n",
    "5. **Analysis:**  \n",
    "   \"What are the pros and cons of using time-series databases like Timestream?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Non-Streaming Chat\n",
    "\n",
    "If you prefer to get the complete response at once (no streaming), use this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to use non-streaming mode\n",
    "# prompt = \"What is machine learning?\"\n",
    "# print(f\"Prompt: {prompt}\\n\")\n",
    "# print(\"Getting response...\\n\")\n",
    "\n",
    "# response = bedrock.invoke(prompt, max_tokens=500)\n",
    "# print(f\"Response:\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
